---
title: "[운영체제] 메모리 관리 (1)"
excerpt: "Memory Management (1)"
toc: true
toc_sticky: true
toc_label: "주요 목차"
header:
  teaser: /assets/images/operating-system.png

date: 2022-01-19T20:50:06+09:00

categories:
  - OS

tags:
  - Programming
  - 프로그래밍
  - 컴퓨터
  - Computer
  - Computer science
  - Computer engineering
  - 컴퓨터 공학
  - 컴퓨터 과학
  - Operating System
  - 운영체제
  - Memory Management
  - 메모리 관리
  - Logical Address
  - Physical Address
  - 주소 바인딩
  - Address Binding
  - MMU
  - Memory-Management Unit
  - Dynamic Loading
  - Overlays
  - Swapping
  - Dynamic Linking
 
last_modified_at: 2022-01-19T20:50:06+09:00
---

## Memory Management (1)

<div class="notice">
    <h4>
        🔊 이화여자대학교 반효경 교수님의 KOCW 2014년 1학기 운영체제 강의를 들으며 정리한 노트입니다.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;캡쳐한 이미지 중 따로 출처 명시를 하지 않은 이미지 또한 반효경 교수님 강의 자료에 있음을 밝힙니다. 
    </h4>
</div>
### Logical vs. Physical Address

> 메모리라는 것은 주소를 통해서 접근하는 매체이다.

- <span style='color: pink'>***<u>Logical address</u>***</span><span style='color: #87ceeb'>(=*virtual address*)</span>

  > 논리적인 주소 (가상 주소라고도 부름)

  - 프로세스마다 독립적으로 가지는 주소 공간
  - 각 프로세스마다 0번지부터 시작
  - CPU가 보는 주소는 logical address임

- <span style='color: pink'>***<u>Physical address</u>***</span>

  > 물리적인 주소

  - 메모리에 실제 올라가는 위치

＊주소 바인딩: 주소를 결정하는 것<br><img src="https://user-images.githubusercontent.com/78403443/150047127-6e595e24-a9f7-4dfb-a5fa-750528797342.png" alt="image" style="zoom:50%;" />

> 프로그래머 입장에서는 숫자로 된 주소를 사용하지 않고, 변수명이나 함수명 같은 Symbol로 된 주소를 사용함. 그것을 여기서 Symbolic Address라고 한다. 이것이 컴파일이 되면 0번지부터 시작하는 그 프로그램만의 독자적인 숫자로 된 주소로 만들어져 바뀌게 된다. 이게 실행이 되려면 물리적인 메모리에 올라가야되니까 주소 변환이 이루어져야 되는 것이다.
>
> 그러면 이 주소 변환이 언제 이루어지는가? (아래)

#### 주소 바인딩 (Address Binding)

> 크게 3가지 시점으로 나눠볼 수 있다.

- <span style='color: pink'>***<u>Compile time binding</u>***</span>

  > 주소 변환이 컴파일 시에 이뤄지는 방법

  - 물리적 메모리 주소(physical address)가 컴파일 시 알려짐
  - 시작 위치 변경시 재컴파일
  - 컴파일러는 절대 코드(<span style='color: #87ceeb'>*<u>absolute code</u>*</span>) 생성

- <span style='color: pink'>***<u>Load time binding</u>***</span>

  > 실행이 시작될 때 주소 변환이 이루어지는 것

  - Loader의 책임하에 물리적 메모리 주소 부여
  - 컴파일러가 재배치가능코드(<span style='color: #87ceeb'>*<u>relocatable code</u>*</span>)를 생성한 경우 가능

- <span style='color: pink'>***<u>Execution time binding (=Run time binding)</u>***</span>

  > 프로그램이 시작된 이후에도 실행하다가 중간에 물리적인 메모리 주소가 바뀔 수 있는 방법

  - 수행이 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있음
  - CPU가 주소를 참조할 때마다 binding을 점검 (address mapping table)
  - <span style='color: #87ceeb'><u>하드웨어적인 지원이 필요</u></span><br>(e.g., *base* and *limit registers, MMU*)

> 이 3가지를 비교하는건 아래 그림을 통해서 보면 쉽다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150048662-8a0c6b78-f478-45c0-b518-765aafafef32.png" alt="image" style="zoom:50%;" />
>
> 맨 왼쪽에 소스코드가 있다. 무슨 언어로 된 프로그램인지는 모르지만 프로그램이 하나 만들어져있다. 이 프로그램에는 Symbolic address로 주소가 표현이 되있다. `Add A, B`는 A 위치에 있는 값 100하고 B 위치에 있는 값 330을 더해서 A 위치에다가 저장하라는 뜻이라고 정의한 것이다. 이 연산결과 A 위치에 100이었던 것이 두개가 더해지니까 430이 될 것이다. `Jump C`는 C 위치로 점프를 하라는 얘기다.<br>Symbolic address로 프로그래머는 메모리 주소를 사용한다는 것을 보여준 코드이다. 이게 컴파일이 되서 실행파일이 만들어지게 되면 Symbolic address였던게 숫자로 된 주소로 바뀌게 된다. 그게 프로그램마다 가지는 주소이기 때문에 여기서는 Logical address가 되는 것이다. 그래서 소스코드의 각각의 문장들이 메모리에 0번지, 10번지, 20번지, 30번지, 40번지 이런식으로 표시가 되고, `Add A, B`하라고 했던게 20번지에 있던 내용과 30번지에 있던 내용을 더하라는 이런식의 주소로 바뀌게 된다. 그 다음에 `Jump C`라고 했던 부분이 40번지로 점프해라 이런식으로 바뀌어서 이 프로그램의 Logical address로 표시가 된 것이다.
>
> 이게 실행이 되려면 물리적인 메모리에 올라가야되고, 물리적인 메모리에 주소가 결정되는 것을 우리가 주소 바인딩이라고 부른다는 것이다. 그 물리적인 메모리 주소가 결정되는 시점이 앞에서 봤듯이 3가지로 나눠볼 수 있었다. 
>
> 그 중에서 제일 위에 나와있는 Compile time binding은 컴파일 시점에 이미 물리적인 메모리 주소가 결정이 되는 것이다. 즉, 컴파일 이후의 Logical address, 논리적인 주소라고 얘기했지만 Compile time binding은 컴파일 시점에 이미 물리적인 주소가 결정이 되야되기 때문에 이 Logical address가 사실은 물리적인 주소라는 것이다.<br>그래서, 이 Compile time binding을 쓰게 되면 이 프로그램을 물리적인 메모리에 올릴 때는 항상 Logical address에 주어져있는(이미 결정되있는) 이 주소로 올려야 된다는 것이다. 즉, 물리적인 메모리에 다른 주소는 많이 비어있는데도 불구하고 항상 이 프로그램은 0번지부터 정해져있는 위치에만 올려야 된다는 것이고, 이게 컴파일 타임에 미리 결정되기 때문에 대단히 비효율적이다.<BR>지금의 컴퓨터 시스템에서는 이런 Compile time binding을 사용하지는 않는다. 그렇지만, 예전에 컴퓨터 안에서 프로그램이 하나만 실행되는 그런 환경에서는 어차피 다른 프로그램이 같이 올라갈 일이 없기 때문에 컴파일 할 때 미리 물리적인 메모리 주소를 결정해서 올리는 이런 방법이 사용되기도 했었다.
>
> 두번째 나와있는 Load time binding은 프로그램이 시작되서 메모리에 올라갈 때 물리적인 메모리 주소가 결정이 되는 것이다. 그래서 이 프로그램에 논리적인 주소가 0번부터 주어져있고, 컴파일 타임에는 논리적인 주소까지만 결정이 된 상태에서 이것을 실행시키게 되면 메모리를 봤더니 물리적인 메모리에 500번지부터 비어있더라... 그러면, "논리적인 주소 0번지를 물리적인 메모리 500번지부터 올린다." 이런 얘기다. 이게 Load time binding이라는 것이다.
>
> 그 다음에 세번째에 나와있는 Run time binding은 Load time binding처럼 실행시에 주소가 결정되는 것은 똑같다. 그런데, 이 주소가 실행 도중에 바뀔 수가 있다는 것이다. 이미지를 보면 논리 주소 0번지가 물리적인 메모리 주소 300번지에 올라와있는데 일단 이렇게 바인딩이 됐다가 실행되는 도중에 300번지부터 있던 이 내용이 700번지부터로 이동해갈 수가 있다는 것이다. 즉, 프로그램이 실행되다가 경우에 따라서는 이런 내용이 300번지부터 올라와있었는데 메모리에서 쫓겨날 수가 있고, 그리고나서 나중에 또 다시 올릴 때는 300번지에 다른 내용이 올라가 있다면 비어있는 700번지에다가 바인딩을 해서 올리고... 이런 것이 지원이 되는게 바로 Run time binding이라는 것이다.<br>그래서, 지금의 우리들이 사용하는 컴퓨터 시스템은 당연히 Run time binding을 지원 하고 있다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150055186-cbad351d-f0bc-44ca-b140-c5f619a03dd2.png" alt="image" style="zoom:50%;" />
>
> Compile time binding을 사용할 때는 이 주소가 논리적인 주소이지만 또 물리적인 메모리 주소로 fix가 되는 것이기 때문에 Compile time binding에 의해서 만들어진 이런 코드를 우리가 absolute code(절대 코드)라고 부른다. 그래서, Compile time binding에 의한 코드는 만약에, 메모리에 올라갈 위치를 바꾸고 싶으면 컴파일을 다시 해야된다. 예를 들어, 물리적인 메모리 0번지부터 올리는게 아니라 500번지부터 올리게 하고 싶다. 그런데 지금 Compile time binding을 쓰겠다그러면 컴파일을 새로해야지 올라갈 수 있는 위치를 바꿀 수가 있는 것이다. 절대 코드 이기 때문에 그런 것이다.
>
> 반면에, Load time binding을 쓰는 데서는 Run time binding도 마찬가지겠지만 컴파일을 해서 만들어지는 논리적인 코드가 재배치가능코드(relocatable code)라고 해서 이것은 항상 특정 위치에 올라가야되는게 아니라 비어있는 위치는 실행 시에 어느 위치든지 올라갈 수 있는 그런 코드라는 것이다.
>
> 그래서, Compile time binding이나 Load time binding은 프로그램이 시작될 때 이미 주소가 다 결정이 되고 그 주소가 변화가 없는데, Run time binding은 프로그램 실행 중에도 계속 주소가 바뀐다는 것이다.<BR>그렇기 때문에, CPU가 어떤 메모리 주소를 요청할 때마다 그때마다 바인딩을 체크를 해봐야 된다. 이 내용이 물리적인 메모리 어디에 올라가 있는지를 주소 변환을 그때그때 해야된다는 것인데 그러기 위해서는 Run time binding은 하드웨어적인 지원이 필요하다. MMU라는 하드웨어가 있어서 그때그때 주소 변환을 해줘야되는게 바로 Run time binding 기법이 되겠다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150056882-60906eda-8aa0-4361-a89d-5defbeb6c888.png" alt="image" style="zoom:50%;" />
>
> 그러면 CPU가 바라보는 주소는 Logical address일까, Physical address일까?<br>CPU는 하드웨어이기 때문에 Physical address를 바라볼 것 같지만 사실은, CPU가 바라보는 주소는 바로 위에 보이는 것 같이 Logical address이다.<BR>이게 이렇게 될 수 밖에 없는 이유가...
>
> <img src="https://user-images.githubusercontent.com/78403443/150048662-8a0c6b78-f478-45c0-b518-765aafafef32.png" alt="image" style="zoom:50%;" />
>
> 이 그림을 잘보면 이해를 할 수 있는데, 우리가 왼쪽과 같은 소스코드로 짜여진 프로그램을 컴파일해서 실행파일을 만들게 되면 그 안 각각이 인스트럭션들인데, CPU가 이러한(실행파일 0번지와 같은) 인스트럭션을 실행하려면 메모리 20번지에 있는 내용과 메모리 30번지에 있는 내용을 CPU로 읽어들여서 더하는 연산을 해야될 것이다. 그런데, 현재 실행파일 0번지에 표시되있는 20번지하고 30번지는 Logical address이다. 그리고 이게 실행이 되서 메모리에 올라가더라도 이 인스트럭션 코드 안에 있는 address는 바뀌지가 않는다. 그대로 20, 30이라고 되어있다. 이것들이 올라가는 위치는 0번지부터 시작하던 실행파일 코드가 500번지부터 또는 300번지부터 올라가는 식으로 되있지만 실제로 이 컴파일된 코드 자체 들어가있는 주소까지 바꿀 수는 없다. 그렇게 되면 컴파일을 새로 해야되는 문제이기 때문에...<br>그래서, 이게 메모리에 올라갈 때 시작위치는 바뀌지만 그 안에 있는 코드 상의 주소는 고스란히 Logical address로 남아있을 수 밖에 없다. 그래서 CPU가 예를 들어서 메모리 500번지에 올라가 있는 `Add 20, 30` 이런 인스트럭션을 실행하겠다 그러면 20번지에 있는 내용과 30번지에 있는 내용을 더하려고 하면 20번지 30번지에 있는 (메모리에 있는) 내용을 CPU안으로 읽어 들여야하는데 그 주소가 Logical address라는 것이다.<BR>즉, CPU가 바라 보는 주소도 Logical address일 수밖에 없다. 그래서 CPU가 매번 메모리 몇번지에 있는 내용을 달라 이렇게 요청을 하면 그때 주소변환을 해서 물리적인 메모리 위치를 찾은 다음에 그 내용을 읽어서 CPU한테 전달을 해야되는 것이다.<BR>그래서, CPU는 Logical address를 본다고 얘기하는 것이다.

> 아까 전에 Run time binding이 지원되려면 하드웨어적인게 필요하다고 말했는데... Compile time binding이나 Load time binding은 사실 주소 변환이라고 해도 별게 없다. Compile time binding는 이미 결정이 되있는거고, Load time binding은 숫자 얼마를 더해주는 그런 바인딩인데,<br>Run time binding부터는 그때그때마다 이 내용들이 어디에 올라가 있는지를 주소 변환을 새로 해주는 방법이 필요하기 때문에 주소 변환용 하드웨어 지원이 필요하다는 것이다.<br>그래서, 주소 변환을 지원해주는 하드웨어를 우리가 MMU(Memory-Management Unit)라고 부른다.

<div class="notice">
    <p>
        🔊 지금 앞부분에서 설명하고 있는 이 내용은 프로그램이 메모리에 올라갈 때 통째로 메모리에 올라가는 그런 경우를 설명하고 있는 것임.
    </p>
    <p>
        지금까지 일반적으로 설명한 현재 프로그램 실행이 되는 상황에서는 프로그램에서 필요한 부분만 메모리에 올라가고, 그렇지 않은 부분은 디스크에 쫓겨나고 각각의 코드도 잘려서 여기저기 산발적으로 올라가고...<br>이런 환경을 이번 메모리 관리에 들어오기 전에 미리부터 설명했었는데, 그것은 현대의 OS가 그렇게 하기 때문에 그렇게 설명을 한 거지만, 지금 메모리 관리로 들어와서는 처음부터 설명을 하는 것이기 때문에 일단은 프로그램의 논리 주소가 통째로 물리적인 메모리에 올라가는 그런 환경을 가정하고 주소 변환을 설명하는 것이다.
    </p>
</div>

##### Memory-Management Unit (MMU)

> 주소 변환을 위한 하드웨어

- <span style='color: pink'>***<u>MMU (Memory-Management Unit)</u>***</span>
  - <span style='color: #87ceeb'>*logical address*</span>를 <span style='color: #87ceeb'>*physical address*</span>로 매핑해주는 <span style='color: #87ceeb'>*Hardware device*</span>
- MMU scheme
  - 사용자 프로세스가 CPU에서 수행되며 생성해내는 모든 주소값에 대해 <span style='color: #87ceeb'>*base register (=relocation register)*</span>의 값을 더한다
- user program
  - <span style='color: #87ceeb'>*logical address*</span>만을 다룬다
  - 실제 <span style='color: #87ceeb'>*physical address*</span>를 볼 수 없으며 알 필요가 없다

> 주소 변환을 할 때는 기본적인 MMU에서는 레지스터 2개를 통해서 주소 변환을 하게 된다.

|                    **Dynamic Relocation**                    |
| :----------------------------------------------------------: |
| <img src="https://user-images.githubusercontent.com/78403443/150073858-6c9b6bf1-8014-41da-9f4b-f7dec889e90b.png" alt="image" style="zoom:50%;" /> |

> CPU가 "메모리 346번지에 있는 내용을 달라" 이렇게 하게 되면 이것은 logical address라고 했다.<BR>그러면, 주소 변환이 필요한데 이 주소 변환을 해주는 하드웨어 MMU라고 했다.<BR>그리고, MMU의 가장 간단한 MMU 주소 변환은 레지스터 2개로 주소 변환이 이루어진다. 그 레지스터는 relocation register(base register라고도 부름), limit register 이 2개를 이용해서 주소 변환을 하게 된다.<br>좌측 하단에 있는 그림은 특정 프로그램 즉, `process p1`이 CPU에서 실행 중인 상황을 나타내고 있어서 `p1`의 logical memory를 나타내주고 있다. 0번지부터 3000번지까지 있고, 그래서 CPU가 346번지를 달라고 했다면, 이 `process p1`의 주소 공간에서 0번지부터 346번째 떨어져있는 내용을 지금 CPU가 요청한 상황이다.
>
> 그리고, 지금 이 프로그램이 physical memory상에는 14000번지부터 올라가 있는 상황이다. 그럼 주소 변환을 어떻게 해주면 되느냐?<br>이 프로그램이 물리적인 메모리에 올라가있는 시작 위치(14000번지)하고, 이 논리주소(346번지)를 더해주면 된다.
>
> 그러면, 14000번지가 논리적인 주소 0번지이기 때문에 14000번부터 346만큼 떨어진 그 위치에 있는 내용을 읽어서 CPU한테 갖다주면 될 것이다.
>
> 이 MMU scheme에서는 base register에다가 이 프로그램의 시작 위치를 갖다가 저장해놓는다. 그래서 주소 변환을 할 때는 논리 주소에다가 시작 위치를 더해서 `14346번지` 이렇게 물리적인 주소를 얻게 된다는 것이다.
>
> 근데, 여기서 한 가지 더 체크하는게 있는데 그것은 바로 limit register를 사용하는 체크이다.<br>이것은 뭐냐하면 이 프로그램의 최대크기가 있을 것이다. `p1`이라는 프로그램은 크기가 3000번지까지 가지고 있는 프로그램이다. 그래서, limit register는 이 프로그램의 크기인 3000을 담고 있다.<br>이렇게 저장해놓는 이유는 이 프로그램이 만약, 악의적인 프로그램이라서 본인의 크기가 3000인데도 불구하고, CPU 중간에 인스트럭션을 통해서 "메모리 4000번지에 있는 내용을 달라" 이런식으로 요청을 할 수도 있다. 그렇게 되면, 이 프로그램은 지금 3000번지까지 밖에 없는데, 만약에 logical address 4000번지를 달라고 하면 4000에다가 시작 위치를 더해주면 그 위치가 physical memory에 정해져 있는 위치 가 아니라 더 바깥이 될 것이다. 3000번지에다가 14000을 더한 17000이 이 프로그램의 제일 끝 부분인데, 있지도 않은 4000번지를 달라고 해서 주소 변환을 해버리면 18000번지... 이 프로그램 바깥에 즉, 다른 프로그램이 존재하는 그런 메모리 위치를 요청하게 되는 것이다.
>
> 그런 경우에는 어떻게 해야될까?<br>요청한다고 주면 안될 것이다! 남의 프로그램 메모리를 보려고 하는 악의적인 시도를 하는 프로그램이기 때문에, 막아야 한다!

|         **Hardware Support for Address Translation**         |
| :----------------------------------------------------------: |
| <img src="https://user-images.githubusercontent.com/78403443/150077497-f170038e-0710-45c0-8d19-4b7b1f790c25.png" alt="image" style="zoom:50%;" /> |

운영체제 및 사용자 프로세스 간의 메모리 보호를 위해 사용하는 레지스터

- <span style='color: pink'>***<u>Relocation register (=base register)</u>***</span>: 접근할 수 있는 물리적 메모리 주소의 최소값
- <span style='color: pink'>***<u>Limit register</u>***</span>: 논리적 주소의 범위

> 그래서, CPU가 메모리 몇 번지를 달라고 논리 주소를 주게 되면, 먼저, 혹시 이 논리 주소가 프로그램 크기보다 더 큰 논리 주소를 요청한 것은 아닌가? 그것부터 체크해본다.<BR>limit register에 있는 값하고 logical address 요청된 것을 비교해보는 것이다. 그래서, limit register의 값을 벗어나는 요청이면 trap이 걸리게 된다. trap이 걸리면 이 프로그램이 CPU를 잡고 있었지만 하던 일을 잠시 멈추고, CPU 제어권이 운영체제한테 넘어가게 된다. 그러면, 운영체제는 trap이 왜 걸렸는지... (trap은 일종의 software interrupt 이다) 왜 걸렸는지 따져보니까 이 프로그램이 악의적이게도 본인의 메모리 주소 아닌 곳을 보려는 시도를 했다고해서 거기에 대한 (프로그램을 강제 abort(중단)시키는 등의) 응징을 한다.
>
> 그렇지 않고, 이 logical address가 프로그램 크기 이내에 있는 그러한 요청이었다면, base register(relocation register)의 값을 더해서 주소 변환을 한 다음에 물리적인 메모리 어딘가에 있는 내용을 읽어다가 CPU한테 전달을 해주면 되는 것이다.
>
> 그게 register 2개를 이용한 간단한 MMU scheme이라는 것이다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150079785-daec797b-04ec-4a66-92f6-558b4169b59e.png" alt="image" style="zoom:50%;" />
>
> 그래서, 사용자 프로그램은 logical address만 다루고 있다.<br>그리고, 실제 physical address는 볼 수도 없고 알 필요도 없다.<br>사용자 프로그램은 logical address를 다루고 있고, CPU도 logical address를 바라보고 있고...
>
> 그래서 physical address라는 것은 logical address로 메모리 주소 요청이 됐을 때, MMU가 그때그때 주소 변환을 해서, 얻게 된다는 그런 개념이다.

### 몇 가지 용어 설명 (Some Terminologies)

- <span style='color: pink'>***<u>Dynamic Loading</u>***</span>
- <span style='color: pink'>***<u>Dynamic Linking</u>***</span>
- <span style='color: pink'>***<u>Overlays</u>***</span>
- <span style='color: pink'>***<u>Swapping</u>***</span>

#### Dynamic Loading

- 프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 해당 루틴이 불려질 때 메모리에 load하는 것
- *memory utilization*의 향상
- 가끔식 사용되는 많은 양의 코드의 경우 유용
  - 예: 오류 처리 루틴
- 운영체제의 특별한 지원 없이 프로그램 자체에서 구현 가능 (OS는 라이브러리를 통해 지원 가능)

＊ Loading: 메모리로 올리는 것

> 메모리에 동적으로 올린다...<BR>프로그램을 메모리에 올려야지 실행이 될텐데 메모리에다가 동적으로 올린다. 이건 무슨 뜻일까?<BR>동적으로 올린다는건 그때그때 필요할 때마다 즉, 해당 루틴이 불려질 때마다 그 루틴을 메모리에 올리는 방법을 Dynamic Loading이라고 부른다.
>
> 즉, 프로그램이 시작될 때 메모리에 통째로 올려놓는다면 (동적 로딩하고 비교해서 설명한다면 이런 용어를 많이 쓰진 않지만) Static Loading(정적 로딩)정도가 되겠다.
>
> 대개 프로그램이라는 것은 방어적으로 만들어지기 때문에, 프로그램 전체 메모리가 균일하게 사용되는게 아니다. 대개 프로그램 중에서 상당 부분은 거의 사용되지 않는 오류 처리 루틴과 같은 것들이 많고... 그래서, 자주 사용되는 부분은 굉장히 한정적인데, 좋은 프로그램 일수록, 좋은 소프트웨어 일수록 그렇다.<br>아주 이상한 input에 대해서도 처리가 가능하게 방어적으로 프로그래밍을 하기 때문에, 일반적으론 사용안되는 그런 루틴들이 대단히 많이 포함이 되있다는 것이다. 
>
> 그것을 통째로 메모리에 올리는 것은 비효율적이기 때문에 미리 올려놓는게 아니라 혹시 그런 상황이 생기면 그때 메모리에 올려놓는 이런 방법을 Dynamic Loading이라고 부른다.
>
> 근데 여기서 Dynamic Loading의 개념은 조금 정교하게 알아둬야할 부분이 있는데 지금 컴퓨터 시스템도 프로그램을 실행시키면 통째로 메모리에 올라가지 않고, 당장 필요한 부분만 메모리에 올라가고 필요없으면 쫓겨나고 이렇게 된다. 근데, 그게 원래 Original Dynamic Loading의 개념은 아니다.<br>지금 우리가 프로그래밍을 해놓으면 필요할 때 그때 메모리에 올라가고 필요 없어지면 쫓겨나고 그거는 운영체제가 관리해주는 소위, 페이징 시스템에 의해서 이루어지는 것이다. (페이징 시스템은 뒷 부분에 나온다고 함)
>
> 여튼, 지금의 일반적인 OS에서 하는 페이징 기법에서의 올라가고 내려가고 하는 것은 운영체제가 직접 관리해주는 것이고, 보통 Dynamic Loading이라고 하면 운영체제가 지원을 해주는게 아니고 프로그래머가 Dynamic Loading을 직접 하도록 만드는... Dynamic Loading은 그런 개념이다.
>
> 그러면, 프로그래머가 수작업으로 언제 어디다가 올리고 이런걸 다 작성하느냐? 하면 그렇지는 않다. 대개 다이나믹 로딩을 프로그래머가 쉽게 하도록 운영체제가 라이브러리 형태로 다이나믹 로딩을 할 수 있는 것을 제공해주고 그것을 통해서 프로그래머는 라이브러리를 써서 만들기 때문에... 일일히 다이나믹 로딩을 어떻게 할지를 만드는건 아니고, 라이브러리를 써서 다이나믹 로딩을 하기 때문에 그렇게 코딩이 어려운 것은 아니다.
>
> 그렇지만, 현재 시스템에서 이루어지는 페이징 기법하고 다이나믹 로딩은 원래는 다른 것이다.<BR>(지금은 다이나믹 로딩이라는 말을 섞어서 쓰기도 한다. 프로그래머가 명시적으로 다이나믹 로딩을 해서 이루어지는게 원래 다이나믹 로딩이지만, 프로그래머가 명시적으로 명시하지 않고, 운영체제가 알아서 올려놓고 쫓아내고 이러는 것도 다이나믹 로딩이라는 말로 섞어쓰기도 한다. 라는 그런 정도로 알아두면 된다.)

> Dynamic Loading하고 구분해서 살펴봐야 될 용어로 Overlays 라는게 있다.

#### Overlays

- 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올림
- 프로세스의 크기가 메모리보다 클 때 유용
- 운영체제의 지원없이 사용자에 의해 구현
- 작은 공간의 메모리를 사용하던 초창기 시스템에서 수작업으로 프로그래머가 구현
  - <span style='color: #87ceeb'>"Manual Overlay"</span>
  - 프로그래밍이 매우 복잡

> 내용을 보면 다이나믹 로딩과 거의 똑같다. Overlays의 첫번째 문장내용만 봐서는 다이나믹 로딩과 오버레이는 차이가 없는데... 역사적으로 조금 다르다.
>
> 오버레이는 초창기 컴퓨터 시스템에서 워낙 메모리 크기가 작기 때문에 프로그램 하나를 메모리에 올려놓는 것 마저도 불가능했다. 그래서, 프로그래머가 프로그램을 메모리에 올려서 실행시킬 때는 큰 프로그램을 쪼개가지고... (이번에는 이쪽 부분을 메모리에 올려놓고 실행을 하고, 그러다가 그 부분이 아니라 다른 부분이 실행이 되어야되면 다른 부분을 또 메모리에 올려놓고) 이런거를 프로그래머가 수작업으로 코딩을 한 것이다.<br>그래서, 이 오버레이를 다른 말로 Manual Overlay라고 함. 대단히 불편하고 어려운 프로그래밍이 될 것이다.
>
> 이것은 운영체제의 지원이 없고, 프로그래머가 직접 어떻게 올리고 내릴지를 코딩을 통해서 다 해야되기 때문에 첫번째 나와있는 실제로 필요한 정보만 올리는 것을 프로그래머가 코딩을 통해서 하는 것이고, Dynamic Loading도 결과적으로는 그렇게 되지만 그거를 라이브러리를 통해서 하기 때문에 프로그래머가 어떻게 올리고 내리는지를 자세하게 코딩 할 필요는 없다는 것이다.
>
> 그게 Dynamic Loading과 Overlays의 차이점이 되겠다.

#### Swapping

- <span style='color: pink'>***<u>Swapping</u>***</span>

  - 프로세스를 일시적으로 메모리에서 <span style='color: #87ceeb'>*backing store*</span>로 쫓아내는 것

    > 하드디스크 같이 메모리에서 쫓겨나는 것을 저장하는 곳을 Backing store라고 부르고 다른 말로는 swap area라고도 부른다.

- <span style='color: pink'>***<u>Backing store (=swap area)</u>***</span>

  - 디스크
    - 많은 사용자의 프로세스 이미지를 담을 만큼 충분히 빠르고 큰 저장 공간

- <span style='color: pink'>***<u>Swap in / Swap out</u>***</span>

  - 일반적으로 중기 스케줄러(swapper)에 의해 swap out 시킬 프로세스 선정
  - priority-based CPU scheduling algorithm
    - priority가 낮은 프로세스를 swapped out 시킴
    - priority가 높은 프로세스를 메모리에 올려놓음
  - Compile time 혹은 load time binding에서는 원래 메모리 위치로 swap in 해야 함
  - Execution time binding에서는 추후 빈 메모리 영역 아무 곳에나 올릴 수 있음
  - swap time은 대부분 transfer time(swap되는 양에 비례하는 시간)임

> 스와핑은 프로세스를 메모리에서 통째로 (하드디스크로) 쫓아내는 것
>
> |                **Schematic View of Swapping**                |
> | :----------------------------------------------------------: |
> | <img src="https://user-images.githubusercontent.com/78403443/150118232-1038ead4-fe8a-48e3-ba40-841f5a0b406b.png" alt="image" style="zoom:50%;" /> |
>
> 메모리에서 통째로 쫓겨나서 하드디스크 backing store로 내려가는 거를 우리가 `swap out`라고 부르고 backing store로 쫓겨났던게 메모리로 다시 올라오는 것을 `swap in`이라고 부른다.
>
> 스와핑하고 관련해서는 중기 스케줄러가 바로 swap out 시킬 프로그램을 결정하는 역할을 하고 있다. 그래서, 중기 스케줄러를 다른 말로 swapper라고도 불렀었다.<br>즉, 메모리에 너무 많은 프로그램이 올라와있으면 시스템이 굉장히 비효율적이 되기 때문에 중기 스케줄러가 일부 프로그램을 골라가지고 통째로 메모리에서 디스크로 쫓아내는 그런 일을 하게 되는데, 그게 스와핑의 개념과 연결되있는 그런 얘기라는 것이다.
>
> 그러면 중기 스케줄러는 보통 어떤 프로그램을 메모리에서 쫓아내느냐? CPU 우선 순위가 낮은(CPU 수행 가능성이 낮은) 프로그램을 쫓아내는게 좋을 것이다. 당장 CPU를 얻어야 될 프로그램은 메모리에 올라와있는게 좋으니까...
>
> 이 스와핑 시스템이 지원이 되기 위해서는 앞에 바인딩하고 연결해서 생각을 좀 해봐야 된다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150048662-8a0c6b78-f478-45c0-b518-765aafafef32.png" alt="image" style="zoom:50%;" />
>
> 만약에, 컴파일 타임 바인딩이나 로드 타임 바인딩이 사용이 되고 있다면, 스와핑에서 쫓겨났다가 메모리로 올라올 때는 원래 위치로 올라와야될 것이다.(500번지에서 쫓겨났으면 500번지로 올라와야되고...다른 메모리 영역이 비어있더라도 반드시 500번지로 올라와야되고) 이렇기 때문에 사실 스와핑의 효과를 십분 발휘하기는 어려울 것이다.<BR>그래서, 스와핑이 좀 더 효율적으로 동작을 하려면 런타임 바인딩이 지원이 되어야 될 것이다. 즉, 300번지부터 올라와있던 프로그램이 스왑 아웃을 당해서 쫓겨났으면 나중에 메모리에 올라갈 때 다른 위치로도 비어있다면 올라갈 수 있게 해주는 그런 방법이 지원이 되는게 좋겠다는 것이다.
>
> 스와핑이 좀 더 효율적으로 사용이 되려면 런타임 바인딩이 지원이 되는 것이 좋겠다는 얘기이다.
>
> <img src="https://user-images.githubusercontent.com/78403443/150118232-1038ead4-fe8a-48e3-ba40-841f5a0b406b.png" alt="image" style="zoom:50%;" />
>
> 메모리에서 프로그램을 통째로 쫓아내고, 다시 올려놓고 이런 일은 상당히 방대한 양이 한꺼번에 쫓겨났다가 다시 올라오는 일이기 때문에(그냥 파일 입출력하고 다르게 양이 굉장히 많다), 이런 디스크 접근하는 시간의 대부분이 Transfer time 즉, 스왑되는 데이터 양에 비례하는 그런 시간이다.<br>우리가 디스크를 접근하는 시간은 (뒤에 하드디스크 스토리지 관리 부분에서 배우겠지만) seek time(탐색시간)이라고 해서 디스크 헤드가 이동하는 시간이 거의 대부분을 차지한다. 그리고 실제로, 데이터를 전송하는 transfer time은 굉장히 미미한 시간 규모를 차지하고 있다.<br>그렇지만, 용량이 이렇게 방대한 스와핑 시스템에서는 seek time도 중요하지만 양이 워낙 많기 때문에 transfer time도 상당 부분을 차지하고 있다라는 설명을 하기 위해서 이런 얘기를 하는 것이다.
>
> 지금 설명한 스와핑은 프로그램이 메모리에서 통째로 쫓겨나는 것을 우리가 스와핑이라고 부르고, 원래 본연의 스와핑의 의미가 이게 맞다.<br>그렇지만, 이것도 최근에는 우리가 페이징 시스템에서 프로그램 전체가 쫓겨나는게 아니라 프로그램 주소 공간이 잘게 잘려져가지고 일부 페이지가 메모리에서 쫓겨나고, 일부 페이지는 또 올라오고 이런식으로 다 쫓겨나는게 아니라 일부 페이지만 쫓겨나는 것 마저도 그 페이지가 스왑 아웃 됐다. 이런식의 표현을 쓰기도 한다. 그러니까, 메모리에서 프로그램 다 쫓겨나는게 아니라 일부 구성하는 페이지만 쫓겨나는 그런 것도 우리가 스왑 아웃됐다라는 말을 쓰기도 하지만...<br>원칙적인 원래의 스와핑의 개념은 스왑 아웃된다고 하면 프로그램을 구성하는 그 주소 공간이 전부 다 쫓겨나는 것을 스왑 아웃이라고 부르고 그래서 중기 스케줄러하고 연동되서 설명을 하는 것이다.

#### Dynamic Linking

- Linking을 실행 시간(execution time)까지 미루는 기법
- Static linking
  - 라이브러리가 프로그램의 실행 파일 코드에 포함됨
  - 실행 파일의 크기가 커짐
  - 동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 메모리 낭비 (eg. printf 함수의 라이브러리 코드)
- Dynamic linking
  - 라이브러리가 실행시 연결(link)됨
  - 라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 stub이라는 작은 코드를 둠
  - 라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고 없으면 디스크에서 읽어옴
  - 운영체제의 도움이 필요

**[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}**